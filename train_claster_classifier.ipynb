{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_VAUkJmgEdX"
   },
   "source": [
    "# Klasyfikator klastr√≥w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laxkoQ58ggfA"
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8W9ttzHf99W",
    "outputId": "5693aedd-35e6-4ee5-a49b-28c13dd816ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comet-ml in ./.venv/lib/python3.12/site-packages (3.47.3)\n",
      "Requirement already satisfied: everett<3.2.0,>=1.0.1 in ./.venv/lib/python3.12/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in ./.venv/lib/python3.12/site-packages (from comet-ml) (4.23.0)\n",
      "Requirement already satisfied: psutil>=5.6.3 in ./.venv/lib/python3.12/site-packages (from comet-ml) (6.1.0)\n",
      "Requirement already satisfied: python-box<7.0.0 in ./.venv/lib/python3.12/site-packages (from comet-ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in ./.venv/lib/python3.12/site-packages (from comet-ml) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in ./.venv/lib/python3.12/site-packages (from comet-ml) (2.32.3)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in ./.venv/lib/python3.12/site-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in ./.venv/lib/python3.12/site-packages (from comet-ml) (2.18.0)\n",
      "Requirement already satisfied: simplejson in ./.venv/lib/python3.12/site-packages (from comet-ml) (3.19.3)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in ./.venv/lib/python3.12/site-packages (from comet-ml) (2.2.3)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in ./.venv/lib/python3.12/site-packages (from comet-ml) (1.16.0)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in ./.venv/lib/python3.12/site-packages (from comet-ml) (3.1.1)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in ./.venv/lib/python3.12/site-packages (from comet-ml) (0.22.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from comet-ml) (75.5.0)\n",
      "Requirement already satisfied: rich>=13.3.2 in ./.venv/lib/python3.12/site-packages (from comet-ml) (13.9.4)\n",
      "Requirement already satisfied: configobj in ./.venv/lib/python3.12/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.12/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.18.4->comet-ml) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.18.4->comet-ml) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.18.4->comet-ml) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=13.3.2->comet-ml) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=13.3.2->comet-ml) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install comet-ml"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e45-0lqzgj9j",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:28:52.759169Z",
     "start_time": "2025-01-15T01:28:50.195213Z"
    }
   },
   "source": [
    "import comet_ml\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "45PCWipEgnBU",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:28:12.368328Z",
     "start_time": "2025-01-15T01:28:12.359126Z"
    }
   },
   "source": [
    "# import os\n",
    "\n",
    "# from google.colab import userdata\n",
    "# key = userdata.get('COMET_API_KEY')\n",
    "# os.environ['COMET_API_KEY'] = key"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWG9YAAkgoJc",
    "outputId": "8f44db06-3666-462a-aeef-06af544ec0ba",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:28:52.797332Z",
     "start_time": "2025-01-15T01:28:52.767840Z"
    }
   },
   "source": [
    "def setup_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        # Set default tensor type for cuda\n",
    "        torch.set_default_dtype(torch.float32)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        # Ensure we're using float32 on CPU\n",
    "        torch.set_default_dtype(torch.float64)\n",
    "    return device\n",
    "\n",
    "device = setup_device()\n",
    "\n",
    "print(f\"Using {device} device\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s2k90WCgqQY"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_PJ_NkxgrlL",
    "outputId": "ae8347dc-f12b-4dc8-87d3-adddb446c5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.12/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from datasets) (3.11.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.17.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5vSo6Jsrgs9s",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:28:54.359685Z",
     "start_time": "2025-01-15T01:28:53.738952Z"
    }
   },
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qv7sMSzHjQjJ",
    "outputId": "64ffdebe-8aa1-439f-9d4c-7fc140e25336",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:09:01.105210Z",
     "start_time": "2025-01-15T01:09:01.085363Z"
    }
   },
   "source": [
    "!ls"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "uNu2rfoPgugO",
    "outputId": "1862995f-20a0-46c3-b79c-fe8d77f16ab8",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:28:55.621033Z",
     "start_time": "2025-01-15T01:28:55.530776Z"
    }
   },
   "source": "ds = load_from_disk(\"clustered_dataset\").with_format(\"torch\")",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vON2G2Cxg2H_",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:28:56.204781Z",
     "start_time": "2025-01-15T01:28:56.200667Z"
    }
   },
   "source": [
    "ds"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'artist', 'date', 'genre', 'style', 'description', 'filename', 'image', 'cluster'],\n",
       "        num_rows: 82600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'artist', 'date', 'genre', 'style', 'description', 'filename', 'image', 'cluster'],\n",
       "        num_rows: 10325\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['title', 'artist', 'date', 'genre', 'style', 'description', 'filename', 'image', 'cluster'],\n",
       "        num_rows: 10325\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nAkyAQSKg6Sk",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:28:21.074853Z",
     "start_time": "2025-01-15T01:28:21.065769Z"
    }
   },
   "source": [
    "percent10 = True\n",
    "\n",
    "if percent10:\n",
    "  # Extract 10% of the train set\n",
    "  ten_percent_train = ds[\"train\"].select(range(int(len(ds[\"train\"]) * 0.1)))\n",
    "  # Extract 10% of the test set\n",
    "  ten_percent_test = ds[\"test\"].select(range(int(len(ds[\"test\"]) * 0.1)))\n",
    "  # Extract 10% of the validation set\n",
    "  ten_percent_valid = ds[\"valid\"].select(range(int(len(ds[\"valid\"]) * 0.1)))\n",
    "\n",
    "  # Combine the subsets into a new DatasetDict\n",
    "  ten_percent_dataset = DatasetDict({\n",
    "      \"train\": ten_percent_train,\n",
    "      \"test\": ten_percent_test,\n",
    "      \"valid\": ten_percent_valid\n",
    "  })\n",
    "\n",
    "  ds = ten_percent_dataset"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:29:05.343827Z",
     "start_time": "2025-01-15T01:29:05.337661Z"
    }
   },
   "source": [
    "  # change if not colab\n",
    "  num_workers = 12\n",
    "  pin_memory = True\n",
    "  batch_size = 64\n",
    "  train_loader = DataLoader(\n",
    "      ds[\"train\"],\n",
    "      batch_size=batch_size,\n",
    "      num_workers=num_workers,\n",
    "      shuffle=True,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "  test_loader = DataLoader(\n",
    "      ds[\"test\"],\n",
    "      batch_size=batch_size,\n",
    "      num_workers=num_workers,\n",
    "      shuffle=False,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "  val_loader = DataLoader(\n",
    "      ds[\"test\"],\n",
    "      batch_size=batch_size,\n",
    "      num_workers=num_workers,\n",
    "      shuffle=False,\n",
    "      pin_memory=True,\n",
    "  )"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_eSbu9vjozd"
   },
   "source": [
    "## ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fsIS8DP0imCW",
    "ExecuteTime": {
     "end_time": "2025-01-15T01:29:07.872088Z",
     "start_time": "2025-01-15T01:29:07.643329Z"
    }
   },
   "source": [
    "PATH = \"models/inpating/mse_perceptual/model1.pth\"\n",
    "# model = VGG16Autoencoder()\n",
    "new_model = torch.load(PATH)\n",
    "new_model.eval()\n",
    "new_model.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamil\\AppData\\Local\\Temp\\ipykernel_32260\\1824298818.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_model = torch.load(PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG16Autoencoder(\n",
       "  (encoder): VGG16EncoderWithSkipConnections(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block5): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block6): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): VGG16Decoder(\n",
       "    (block6): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "    )\n",
       "    (block5): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "    )\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (5): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:29:09.946368Z",
     "start_time": "2025-01-15T01:29:09.933706Z"
    }
   },
   "source": [
    "encoder = new_model.encoder\n",
    "encoder.eval()  # Set the encoder to evaluation mode\n",
    "encoder.to(device)  # Move the encoder to the appropriate device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16EncoderWithSkipConnections(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block6): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:29:11.509899Z",
     "start_time": "2025-01-15T01:29:11.503656Z"
    }
   },
   "source": [
    "# Define the MLP model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AdaptedStyleClusterCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),  # Flatten the latent output [batch_size, 128, 4, 4] -> [batch_size, 2048]\n",
    "            \n",
    "            # Fully Connected Layers\n",
    "            nn.Linear(in_features=2048, out_features=128),  # Adjusted in_features\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:29:13.004196Z",
     "start_time": "2025-01-15T01:29:12.995332Z"
    }
   },
   "source": [
    "# Set up model hyperparameters\n",
    "input_size = 2048  \n",
    "num_classes = 20  \n",
    "\n",
    "# Create the model\n",
    "model = AdaptedStyleClusterCNN(num_classes)\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptedStyleClusterCNN(\n",
       "  (model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:29:15.356873Z",
     "start_time": "2025-01-15T01:29:14.347178Z"
    }
   },
   "source": [
    "# pure PyTorch loop\n",
    "num_epochs = 20\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T01:29:18.697231Z",
     "start_time": "2025-01-15T01:29:16.254708Z"
    }
   },
   "source": [
    "from torchinfo import summary\n",
    "from tqdm import tqdm \n",
    "from create_mask import generate_scaled_blob\n",
    "\n",
    "# SET UP COMET ML\n",
    "comet_experiment = comet_ml.Experiment(\n",
    "    api_key=\"LP4wJZSrJYL1KJZ06ahrmPLUb\",\n",
    "    project_name=\"UczenieNienadzorowane\")\n",
    "comet_experiment.log_code(folder=\"/UN\")\n",
    "comet_experiment.log_parameters(\n",
    "    {\n",
    "        \"batch_size\": train_loader.batch_size,\n",
    "        \"train_size\": ds[\"train\"].num_rows,\n",
    "        \"val_size\": ds[\"valid\"].num_rows,\n",
    "    }\n",
    ")\n",
    "input_size = (batch_size, 128, 4, 4)\n",
    "summ = summary(model, input_size, device=device, depth=5)\n",
    "comet_experiment.set_model_graph(f\"{model.__repr__()}\\n{summ}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/kamilciepluch/uczenienienadzorowane/c9f309b3b302484a866f2a780f11c8ab\n",
      "\n",
      "\u001B[1;38;5;196mCOMET ERROR:\u001B[0m We failed to read directory '/UN' for uploading.\n",
      "Please double-check the file path, permissions, and that it is a directory.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T04:27:58.166521Z",
     "start_time": "2025-01-15T01:29:19.847199Z"
    }
   },
   "source": [
    "# train and validate\n",
    "save_model_path = \"models/cluster_clasification/model1_0\"\n",
    "for epoch in range(num_epochs):\n",
    "        comet_experiment.set_epoch(epoch)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "        model.train()\n",
    "        with comet_experiment.train() as train:\n",
    "            for idx, batch in tqdm(enumerate(train_loader), desc=f\"TRAIN_{epoch}\"):\n",
    "                comet_experiment.set_step(idx + epoch * len(train_loader))\n",
    "\n",
    "                optimizer.zero_grad()  # MUST be called on every batch\n",
    "                \n",
    "                images = batch[\"image\"] / 255.0\n",
    "                labels = batch[\"cluster\"]\n",
    "\n",
    "                # Generate and apply mask\n",
    "                masks = generate_scaled_blob(images.shape, mask_percentage=(1 / 16) * 100).float() / 255.0\n",
    "                images_with_mask = images * (1 - masks.unsqueeze(1))\n",
    "                images_with_mask = torch.cat((images_with_mask, masks.unsqueeze(1)), dim=1)\n",
    "\n",
    "                images = images_with_mask.to(device)\n",
    "                \n",
    "                # One-hot encode labels\n",
    "                labels = F.one_hot(labels, num_classes=20).float().to(device)  # Shape: [batch_size, num_classes]\n",
    "\n",
    "                latents, _ = encoder(images)\n",
    "                outputs = model(latents)  # Shape: [batch_size, num_classes=20]\n",
    "\n",
    "                loss = loss_func(outputs, labels)  # BCEWithLogitsLoss expects one-hot encoded labels\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                comet_experiment.log_metric(\"loss\", loss.item())\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            save_model_path = f\"models/cluster_clasification/model1_{epoch}\"\n",
    "            \n",
    "        torch.save(model.state_dict(), save_model_path)\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        with comet_experiment.validate() as validat, torch.no_grad() as nograd:\n",
    "            for idx, batch in tqdm(enumerate(val_loader), desc=f\"VAL_{epoch}\"):\n",
    "                comet_experiment.set_step(idx + epoch * len(val_loader))\n",
    "\n",
    "                images = batch[\"image\"] / 255.0\n",
    "                labels = batch[\"cluster\"]\n",
    "\n",
    "                # Generate and apply mask\n",
    "                masks = generate_scaled_blob(images.shape, mask_percentage=(1 / 16) * 100).float() / 255.0\n",
    "                images_with_mask = images * (1 - masks.unsqueeze(1))\n",
    "                images_with_mask = torch.cat((images_with_mask, masks.unsqueeze(1)), dim=1)\n",
    "\n",
    "                images = images_with_mask.to(device)\n",
    "                \n",
    "                # One-hot encode labels\n",
    "                labels = F.one_hot(labels, num_classes=20).float().to(device)  # Shape: [batch_size, num_classes]\n",
    "\n",
    "                latents, _ = encoder(images)\n",
    "                outputs = model(latents)  # Shape: [batch_size, num_classes=20]\n",
    "\n",
    "                loss = loss_func(outputs, labels)  # BCEWithLogitsLoss expects one-hot encoded labels\n",
    "                comet_experiment.log_metric(\"loss\", loss.item())\n",
    "                "
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN_0: 0it [00:00, ?it/s]C:\\Users\\kamil\\.conda\\envs\\DLF\\Lib\\site-packages\\scipy\\interpolate\\_fitpack_py.py:155: RuntimeWarning: The maximal number of iterations (20) allowed for finding smoothing\n",
      "spline with fp=s has been reached. Probable cause: s too small.\n",
      "(abs(fp-s)/s>0.001)\n",
      "  res = _impl.splprep(x, w, u, ub, ue, k, task, s, t, full_output, nest, per,\n",
      "TRAIN_0: 1291it [08:20,  2.58it/s]\n",
      "VAL_0: 162it [00:34,  4.72it/s]\n",
      "TRAIN_1: 1291it [08:25,  2.55it/s]\n",
      "VAL_1: 162it [00:38,  4.16it/s]\n",
      "TRAIN_2: 1291it [08:26,  2.55it/s]\n",
      "VAL_2: 162it [00:35,  4.63it/s]\n",
      "TRAIN_3: 1291it [08:16,  2.60it/s]\n",
      "VAL_3: 162it [00:33,  4.84it/s]\n",
      "TRAIN_4: 1291it [08:16,  2.60it/s]\n",
      "VAL_4: 162it [00:33,  4.86it/s]\n",
      "TRAIN_5: 1291it [08:16,  2.60it/s]\n",
      "VAL_5: 162it [00:33,  4.84it/s]\n",
      "TRAIN_6: 1291it [08:16,  2.60it/s]\n",
      "VAL_6: 162it [00:33,  4.81it/s]\n",
      "TRAIN_7: 1291it [08:23,  2.56it/s]\n",
      "VAL_7: 162it [00:38,  4.15it/s]\n",
      "TRAIN_8: 1291it [08:26,  2.55it/s]\n",
      "VAL_8: 162it [00:35,  4.60it/s]\n",
      "TRAIN_9: 1291it [08:17,  2.59it/s]\n",
      "VAL_9: 162it [00:33,  4.79it/s]\n",
      "TRAIN_10: 1291it [08:16,  2.60it/s]\n",
      "VAL_10: 162it [00:33,  4.83it/s]\n",
      "TRAIN_11: 1291it [08:17,  2.60it/s]\n",
      "VAL_11: 162it [00:33,  4.82it/s]\n",
      "TRAIN_12: 1291it [08:17,  2.60it/s]\n",
      "VAL_12: 162it [00:33,  4.84it/s]\n",
      "TRAIN_13: 1291it [08:17,  2.60it/s]\n",
      "VAL_13: 162it [00:33,  4.82it/s]\n",
      "TRAIN_14: 1291it [08:23,  2.56it/s]\n",
      "VAL_14: 162it [00:38,  4.18it/s]\n",
      "TRAIN_15: 1291it [08:26,  2.55it/s]\n",
      "VAL_15: 162it [00:35,  4.59it/s]\n",
      "TRAIN_16: 1291it [08:18,  2.59it/s]\n",
      "VAL_16: 162it [00:33,  4.81it/s]\n",
      "TRAIN_17: 1291it [08:17,  2.60it/s]\n",
      "VAL_17: 162it [00:33,  4.84it/s]\n",
      "TRAIN_18: 1291it [08:17,  2.60it/s]\n",
      "VAL_18: 162it [00:33,  4.85it/s]\n",
      "TRAIN_19: 1291it [08:17,  2.60it/s]\n",
      "VAL_19: 162it [00:33,  4.85it/s]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T04:28:33.045308Z",
     "start_time": "2025-01-15T04:27:58.189139Z"
    }
   },
   "source": [
    "model.eval()\n",
    "with comet_experiment.test() as test, torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader), desc=f\"TEST_{num_epochs}\"):\n",
    "        comet_experiment.set_step(idx + num_epochs * len(test_loader))\n",
    "\n",
    "        images = batch[\"image\"] / 255.0\n",
    "        labels = batch[\"cluster\"]\n",
    "\n",
    "        # Generate and apply mask\n",
    "        masks = generate_scaled_blob(images.shape, mask_percentage=(1 / 16) * 100).float() / 255.0\n",
    "        images_with_mask = images * (1 - masks.unsqueeze(1))\n",
    "        images_with_mask = torch.cat((images_with_mask, masks.unsqueeze(1)), dim=1)\n",
    "\n",
    "        images = images_with_mask.to(device)\n",
    "        \n",
    "        # One-hot encode labels\n",
    "        labels = F.one_hot(labels, num_classes=20).float().to(device)  # Shape: [batch_size, num_classes]\n",
    "\n",
    "        latents, _ = encoder(images)\n",
    "        outputs = model(latents)  # Shape: [batch_size, num_classes=20]\n",
    "\n",
    "        loss = loss_func(outputs, labels)  # BCEWithLogitsLoss expects one-hot encoded labels\n",
    "        \n",
    "        comet_experiment.log_metric(\"loss\", loss.item())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST_20: 162it [00:34,  4.74it/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T04:28:33.226625Z",
     "start_time": "2025-01-15T04:28:33.219600Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), f\"models/cluster_clasification/model1_{num_epochs}\")",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T04:28:35.166011Z",
     "start_time": "2025-01-15T04:28:33.285846Z"
    }
   },
   "source": "comet_experiment.end()",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Comet.ml Experiment Summary\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Data:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     display_summary_level : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     name                  : residential_hotel_7799\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     url                   : https://www.comet.com/kamilciepluch/uczenienienadzorowane/c9f309b3b302484a866f2a780f11c8ab\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Metrics [count] (min, max):\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     test_loss [162]      : (0.14885829389095306, 0.17599892616271973)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_loss [28403]   : (0.14596815407276154, 0.6936233639717102)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     validate_loss [3240] : (0.14941684901714325, 0.1939256489276886)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Parameters:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_size : 64\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_size : 82600\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     val_size   : 10325\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Uploads:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     environment details      : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     filename                 : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git metadata             : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git-patch (uncompressed) : 1 (1.69 KB)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     installed packages       : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     model graph              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     notebook                 : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     source_code              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m \n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
